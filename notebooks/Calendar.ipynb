{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concordia Calendar Example\n",
    "\n",
    "This notebook goes through the Calendar example and is a good place to start in order to gain a better understanding of the library and agent/game master interactions.  \n",
    "\n",
    "Since getting a PR merged to fix bugs in this example, I've continued working on updating the phone components for the Mastodon simulation. However, for this example, I'd like you to use the unmodified components (that is, the fixed versions, but not the very latest versions). This worthwhile in order to understand design decisions for the Mastodon sim updates.\n",
    "\n",
    "For reference, you may compare versions:\n",
    "- [Concordia mainline phone components](https://github.com/google-deepmind/concordia/tree/2684366df2e70993bccb2ea3630cbe7cc7d91a7a/examples/phone/components)\n",
    "- [Latest updates for Mastodon sim](https://github.com/social-sandbox/mastodon-sim/tree/main/src/mastodon_sim/concordia/components)\n",
    "\n",
    "To accomplish this, we can start by cloning the mainline repository, in order to be able to import the `examples/phone` components.\n",
    "\n",
    "After this, I'd suggest that before you clear the contents of this notebook, you read through them, and see if you can understand how the main run cell's output aligns with the \"Analyzing this episode\" section below it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the library in editable mode so that we can make changes to the code if necessary, and obtain the examples directory.\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/gdm-concordia/concordia.git\n",
    "cd concordia\n",
    "pip install -e . --config-settings editable_mode=compat\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "# Point this to your cloned Concordia repo directory\n",
    "sys.path.append(\"../concordia\")\n",
    "\n",
    "# Notice that this imports from Concordia examples version, and not the mastodon-sim version\n",
    "from examples.phone.components import apps, triggering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import concurrent.futures\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    import sentence_transformers\n",
    "\n",
    "from concordia import components as generic_components\n",
    "from concordia.agents import basic_agent\n",
    "from concordia.associative_memory import (\n",
    "    associative_memory,\n",
    "    blank_memories,\n",
    "    formative_memories,\n",
    "    importance_function,\n",
    ")\n",
    "from concordia.clocks import game_clock\n",
    "from concordia.components import agent as components\n",
    "from concordia.components import game_master as gm_components\n",
    "from concordia.environment import game_master\n",
    "from concordia.language_model import amazon_bedrock_model, gpt_model\n",
    "from concordia.metrics import (\n",
    "    common_sense_morality,\n",
    "    goal_achievement,\n",
    "    opinion_of_others,\n",
    ")\n",
    "from concordia.utils import html as html_lib\n",
    "from concordia.utils import measurements as measurements_lib\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set LLM and embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gpt-4o\"\n",
    "# MODEL_NAME = \"gpt-4o-mini\"\n",
    "# MODEL_NAME = \"sonnet\"\n",
    "\n",
    "if \"sonnet\" in MODEL_NAME:\n",
    "    model = amazon_bedrock_model.AmazonBedrockLanguageModel(\n",
    "        model_id=\"anthropic.claude-3-5-sonnet-20240620-v1:0\"\n",
    "    )\n",
    "elif \"gpt\" in MODEL_NAME:\n",
    "    GPT_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not GPT_API_KEY:\n",
    "        raise ValueError(\"GPT_API_KEY is required.\")\n",
    "    model = gpt_model.GptLanguageModel(api_key=GPT_API_KEY, model_name=MODEL_NAME)\n",
    "else:\n",
    "    raise ValueError(\"Unknown model name.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup sentence encoder\n",
    "st_model = sentence_transformers.SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "embedder = lambda x: st_model.encode(x, show_progress_bar=False)  # noqa: E731"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the generic knowledge of the players and the game master (GM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_memories = [\n",
    "    \"There is a hamlet named Riverbend.\",\n",
    "    \"Riverbend is an idyllic rural town.\",\n",
    "    \"The river Solripple runs through the village of Riverbend.\",\n",
    "    \"The Solripple is a mighty river.\",\n",
    "    \"Riverbend has a temperate climate.\",\n",
    "    \"Riverbend has a main street.\",\n",
    "    \"There is a guitar store on Main street Riverbend.\",\n",
    "    \"There is a grocery store on Main street Riverbend.\",\n",
    "    \"There is a school on Main street Riverbend.\",\n",
    "    \"There is a library on Main street Riverbend.\",\n",
    "    \"Riverbend has only one pub.\",\n",
    "    \"There is a pub on Main street Riverbend called The Sundrop Saloon.\",\n",
    "    \"Town hall meetings often take place at The Sundrop Saloon.\",\n",
    "    \"Riverbend does not have a park\",\n",
    "    \"The main crop grown on the farms near Riverbend is alfalfa.\",\n",
    "    \"Farms near Riverbend depend on water from the Solripple river.\",\n",
    "    \"There is no need to register in advance to be on the ballot.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The generic context will be used for the NPC context. It reflects general\n",
    "# knowledge and is possessed by all characters.\n",
    "shared_context = model.sample_text(\n",
    "    \"Summarize the following passage in a concise and insightful fashion. \"\n",
    "    + \"Make sure to include information about Mastodon:\\n\"\n",
    "    + \"\\n\".join(shared_memories)\n",
    "    + \"\\nSummary:\",\n",
    ")\n",
    "\n",
    "print(shared_context)\n",
    "importance_model = importance_function.ConstantImportanceModel()\n",
    "importance_model_gm = importance_function.ConstantImportanceModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the clock\n",
    "time_step = datetime.timedelta(minutes=15)\n",
    "\n",
    "SETUP_TIME = datetime.datetime(year=2024, month=10, day=1, hour=8)  # noqa: DTZ001\n",
    "\n",
    "START_TIME = datetime.datetime(year=2024, month=10, day=1, hour=8)  # noqa: DTZ001\n",
    "\n",
    "clock = game_clock.MultiIntervalClock(\n",
    "    start=SETUP_TIME, step_sizes=[time_step, datetime.timedelta(seconds=10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to build the players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank_memory_factory = blank_memories.MemoryFactory(\n",
    "    model=model,\n",
    "    embedder=embedder,\n",
    "    importance=importance_model.importance,\n",
    "    clock_now=clock.now,\n",
    ")\n",
    "\n",
    "formative_memory_factory = formative_memories.FormativeMemoryFactory(\n",
    "    model=model,\n",
    "    shared_memories=shared_memories,\n",
    "    blank_memory_factory_call=blank_memory_factory.make_blank_memory,\n",
    ")\n",
    "\n",
    "# All players get the same `measurements` object.\n",
    "measurements = measurements_lib.Measurements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build agent function\n",
    "\n",
    "\n",
    "def build_agent(\n",
    "    agent_config, measurements: measurements_lib.Measurements, player_names: list[str]\n",
    ") -> tuple:\n",
    "    \"\"\"Build an agent based on the given configuration.\"\"\"\n",
    "    mem = formative_memory_factory.make_memories(agent_config)\n",
    "\n",
    "    time = generic_components.report_function.ReportFunction(\n",
    "        name=\"Current time\",\n",
    "        function=clock.current_time_interval_str,\n",
    "    )\n",
    "\n",
    "    somatic_state = components.somatic_state.SomaticState(model, mem, agent_config.name, clock.now)\n",
    "    identity = components.identity.SimIdentity(\n",
    "        model=model,\n",
    "        memory=mem,\n",
    "        agent_name=agent_config.name,\n",
    "        clock_now=clock.now,\n",
    "    )\n",
    "\n",
    "    current_obs = components.observation.Observation(\n",
    "        agent_name=agent_config.name,\n",
    "        clock_now=clock.now,\n",
    "        memory=mem,\n",
    "        timeframe=time_step * 1,\n",
    "        component_name=\"current observations\",\n",
    "    )\n",
    "    summary_obs = components.observation.ObservationSummary(\n",
    "        agent_name=agent_config.name,\n",
    "        model=model,\n",
    "        clock_now=clock.now,\n",
    "        memory=mem,\n",
    "        timeframe_delta_from=datetime.timedelta(hours=4),\n",
    "        timeframe_delta_until=time_step * 1,\n",
    "        components=[identity],\n",
    "        component_name=\"summary of observations\",\n",
    "    )\n",
    "\n",
    "    initial_goal_component = generic_components.constant.ConstantComponent(\n",
    "        state=agent_config.goal, name=\"overarching goal\"\n",
    "    )\n",
    "\n",
    "    plan = components.plan.SimPlan(\n",
    "        model=model,\n",
    "        memory=mem,\n",
    "        agent_name=agent_config.name,\n",
    "        clock_now=clock.now,\n",
    "        components=[identity],\n",
    "        goal=initial_goal_component,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    agent = basic_agent.BasicAgent(\n",
    "        model=model,\n",
    "        agent_name=agent_config.name,\n",
    "        clock=clock,\n",
    "        verbose=True,\n",
    "        components=[identity, plan, somatic_state, summary_obs, current_obs, time],\n",
    "        update_interval=time_step,\n",
    "    )\n",
    "\n",
    "    return agent, mem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure and build the players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PLAYERS = 3\n",
    "\n",
    "\n",
    "def make_random_big_five() -> str:\n",
    "    \"\"\"Generate a random Big Five personality trait score.\"\"\"\n",
    "    return str(\n",
    "        {\n",
    "            \"extraversion\": random.randint(1, 10),\n",
    "            \"neuroticism\": random.randint(1, 10),\n",
    "            \"openness\": random.randint(1, 10),\n",
    "            \"conscientiousness\": random.randint(1, 10),\n",
    "            \"agreeableness\": random.randint(1, 10),\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "scenario_premise = [\n",
    "    (\n",
    "        \"It's early October in Riverbend, and the town is buzzing with activity .\"\n",
    "        \"The local government has just announced a new initiative to combat the effects of climate change on the river. \"\n",
    "        \"Alice, an environmental activist, and Bob, a small business owner, are both active members of the Riverbend.social Mastodon instance. \"\n",
    "        \"As they go about their daily routines, they use the platform to stay connected, share updates, and engage with the community on this pressing local issue.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "player_configs = [\n",
    "    # === Benign ===\n",
    "    formative_memories.AgentConfig(\n",
    "        name=\"Alice\",\n",
    "        gender=\"female\",\n",
    "        goal=\"Setup a meeting with Bob for two weeks from today using her smartphone.\",\n",
    "        context=f\"{shared_context}\\nAlice grew up in Riverbend.\",\n",
    "        traits=make_random_big_five(),\n",
    "    ),\n",
    "    formative_memories.AgentConfig(\n",
    "        name=\"Bob\",\n",
    "        gender=\"male\",\n",
    "        goal=\"Just chill and enjoy life.\",\n",
    "        context=f\"{shared_context}\\nBob grew up in Riverbend.\",\n",
    "        traits=make_random_big_five(),\n",
    "    ),\n",
    "]\n",
    "\n",
    "player_names = [player.name for player in player_configs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the agents\n",
    "from functools import partial\n",
    "\n",
    "player_configs = player_configs[:NUM_PLAYERS]\n",
    "player_goals = {player_config.name: player_config.goal for player_config in player_configs}\n",
    "players = []\n",
    "memories = {}\n",
    "\n",
    "build_agent_with_arg = partial(build_agent, measurements=measurements, player_names=player_names)\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=NUM_PLAYERS) as pool:\n",
    "    for agent, mem in pool.map(build_agent_with_arg, player_configs):\n",
    "        players.append(agent)\n",
    "        memories[agent.name] = mem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the GM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_master_memory = associative_memory.AssociativeMemory(\n",
    "    embedder, importance_model_gm.importance, clock=clock.now\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some memories to the game master\n",
    "for player in players:\n",
    "    game_master_memory.add(f\"{player.name} is at their private home.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create components and externalities for the game master\n",
    "scenario_knowledge = components.constant.ConstantComponent(\n",
    "    \" \".join(shared_memories), \"General knowledge of Riverbend\"\n",
    ")\n",
    "player_status = gm_components.player_status.PlayerStatus(\n",
    "    clock.now, model, game_master_memory, player_names\n",
    ")\n",
    "\n",
    "relevant_events = gm_components.relevant_events.RelevantEvents(clock.now, model, game_master_memory)\n",
    "time_display = gm_components.time_display.TimeDisplay(clock)\n",
    "\n",
    "direct_effect_externality = gm_components.direct_effect.DirectEffect(\n",
    "    players,\n",
    "    memory=game_master_memory,\n",
    "    model=model,\n",
    "    clock_now=clock.now,\n",
    "    verbose=False,\n",
    "    components=[player_status],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create apps and provide them to the phones, assigning 1 phone to each player\n",
    "calendar_app = apps.ToyCalendar()\n",
    "\n",
    "phones = [apps.Phone(player.name, apps=[calendar_app]) for player in players]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create component to trigger PhoneGameMaster\n",
    "phone_triggering = triggering.SceneTriggeringComponent(\n",
    "    players,\n",
    "    phones,\n",
    "    model,\n",
    "    memory=game_master_memory,\n",
    "    clock=clock,\n",
    "    memory_factory=blank_memory_factory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the game master object\n",
    "env = game_master.GameMaster(\n",
    "    model=model,\n",
    "    memory=game_master_memory,\n",
    "    clock=clock,\n",
    "    players=players,\n",
    "    components=[\n",
    "        scenario_knowledge,\n",
    "        player_status,\n",
    "        direct_effect_externality,\n",
    "        relevant_events,\n",
    "        time_display,\n",
    "        phone_triggering,\n",
    "    ],\n",
    "    randomise_initiative=True,\n",
    "    player_observes_event=False,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clock.set(START_TIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for player in players:\n",
    "    player.observe(f\"{player.name} is at home, they have just woken up.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, please refer to the \"Analyzing the episode\" markdown section below the output of this cell for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expect about 1 minute per step\n",
    "episode_length = 3\n",
    "for _ in range(episode_length):\n",
    "    env.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing this episode\n",
    "\n",
    "**Note:** There is high variability between runs. The following analysis is based on the single run shown above. The above simulation runs three steps, but below we will just break down the first of three (one interaction for each player).\n",
    "\n",
    "1. An agent is [randomly picked](https://github.com/google-deepmind/concordia/blob/53697b2bf2019b4a167bdd1f82d14e085f1a5eba/concordia/environment/game_master.py#L373C13-L373C34) from Bob and Alice -> Alice\n",
    "2. A prompt is created that includes Alice's [context of action](https://github.com/google-deepmind/concordia/blob/53697b2bf2019b4a167bdd1f82d14e085f1a5eba/concordia/agents/basic_agent.py#L178) (the combined state of all her components) and a [call to action](https://github.com/google-deepmind/concordia/blob/53697b2bf2019b4a167bdd1f82d14e085f1a5eba/concordia/typing/entity.py#L51) (question prompt), which is used to generate Alice's [action attempt](https://github.com/google-deepmind/concordia/blob/53697b2bf2019b4a167bdd1f82d14e085f1a5eba/concordia/environment/game_master.py#L327-L329).\n",
    "3. The action attempt is [sent to the main Game Master](https://github.com/google-deepmind/concordia/blob/53697b2bf2019b4a167bdd1f82d14e085f1a5eba/concordia/environment/game_master.py#L207), which determines the outcome of the action attempt. This happens by [passing the action attempt through a thought chain](https://github.com/google-deepmind/concordia/blob/53697b2bf2019b4a167bdd1f82d14e085f1a5eba/concordia/environment/game_master.py#L225). The [thought chain](https://github.com/google-deepmind/concordia/blob/53697b2bf2019b4a167bdd1f82d14e085f1a5eba/concordia/environment/game_master.py#L38), by default is defined by two LLM prompts that are run in serial: \n",
    "    1. `result = thought_chains.attempt_to_result(action_attempt)` Defined [here](https://github.com/google-deepmind/concordia/blob/53697b2bf2019b4a167bdd1f82d14e085f1a5eba/concordia/thought_chains/thought_chains.py#L171), which asks, \"What happens as a result of the attempted action? Take into account the location and status of each player.\"\n",
    "    2. `event_statement = thought_chains.result_to_who_what_where(result)` Defined [here](https://github.com/google-deepmind/concordia/blob/53697b2bf2019b4a167bdd1f82d14e085f1a5eba/concordia/thought_chains/thought_chains.py#L235) which asks, \"Rewrite the statements above into one sentence that highlights the main person, the location, their actions, and the outcome, avoiding uncertainty (e.g., \"Francis opened the door\" instead of \"Francis could open the door\" or \"The door may have been opened\").\"\n",
    "    3. `event_statement` is then added to the Game Master's memory, and [optionally](https://github.com/google-deepmind/concordia/blob/53697b2bf2019b4a167bdd1f82d14e085f1a5eba/concordia/environment/game_master.py#L235) added to the current player's observations.\n",
    "4. The main Game Master runs [`update_after_event` on each component](https://github.com/google-deepmind/concordia/blob/53697b2bf2019b4a167bdd1f82d14e085f1a5eba/concordia/environment/game_master.py#L264-L272) to get the externality from the event.\n",
    "5. Since one of the main Game Master's components is a [`PhoneTriggeringComponent`](https://github.com/google-deepmind/concordia/blob/53697b2bf2019b4a167bdd1f82d14e085f1a5eba/examples/phone/components/triggering.py#L33), this component [runs its `update_after_event` method](https://github.com/google-deepmind/concordia/blob/53697b2bf2019b4a167bdd1f82d14e085f1a5eba/examples/phone/components/triggering.py#L144).\n",
    "6. The `PhoneTriggeringComponent`'s [`_get_player_using_phone(event_statement)` method is run](https://github.com/google-deepmind/concordia/blob/53697b2bf2019b4a167bdd1f82d14e085f1a5eba/examples/phone/components/triggering.py#L111). This does the following, step by step:\n",
    "    1. Checks if the event_statement is a phone event ([prompt](https://github.com/google-deepmind/concordia/blob/53697b2bf2019b4a167bdd1f82d14e085f1a5eba/examples/phone/components/triggering.py#L59)). If False, returns None, which tells the GM to proceed to the next step in the overall episode.\n",
    "    2. If True, starts iterating through each player the main Game Master has access to (both in this case), [checking if the phone event is related to that player](https://github.com/google-deepmind/concordia/blob/53697b2bf2019b4a167bdd1f82d14e085f1a5eba/examples/phone/components/triggering.py#L120C19-L120C41) [(prompt)](https://github.com/google-deepmind/concordia/blob/53697b2bf2019b4a167bdd1f82d14e085f1a5eba/examples/phone/components/triggering.py#L89). If False, moves to next player. If out of players, moves does not continue with phone scene and instead moves to next step.\n",
    "    3. Once it hits one that is True, returns that player\n",
    "7. Since the above process affirmed phone event and player being Alice, [`self._run_phone_scene(player)` is run](https://github.com/google-deepmind/concordia/blob/53697b2bf2019b4a167bdd1f82d14e085f1a5eba/examples/phone/components/triggering.py#L147C7-L147C36).\n",
    "8. The phone scene starts by [building a PhoneGameMaster](https://github.com/google-deepmind/concordia/blob/53697b2bf2019b4a167bdd1f82d14e085f1a5eba/examples/phone/components/triggering.py#L129), providing it the single player that triggered the scene (instead of both players that the main Game Master has access to), as well as a [single component](https://github.com/google-deepmind/concordia/blob/53697b2bf2019b4a167bdd1f82d14e085f1a5eba/examples/phone/components/scene.py#L72), [`_PhoneComponent`](https://github.com/google-deepmind/concordia/blob/53697b2bf2019b4a167bdd1f82d14e085f1a5eba/examples/phone/components/scene.py#L79).\n",
    "9. The clock is then switched to a \"higher gear\", so the time intervals switch from 15mins to 10sec.\n",
    "10. The phone Game Master [calls its `run_episode` method]([phone_scene.run_episode()](https://github.com/google-deepmind/concordia/blob/\n",
    "53697b2bf2019b4a167bdd1f82d14e085f1a5eba/examples/phone/components/triggering.py#L137)) to start a scene in the \"phone universe\".\n",
    "11. The run episode method is the same method defined for the main Game Master, which proceeds to call `.step()` multiple times unless a component's `terminate_episode` method returns True at the end of a step.\n",
    "12. In the first step for the phone Game Master, similar to step (2), for the only player (Alice), an LLM is given this player's components' states plus a new [phone call to action](https://github.com/google-deepmind/concordia/blob/53697b2bf2019b4a167bdd1f82d14e085f1a5eba/examples/phone/components/scene.py#L33) as a prompt. This prompt asks the LLM to says, \"What action is {name} currently performing or has just performed with their smartphone to best achieve their goal? ...\"\n",
    "13. This action attempt is passed through a [null thought chain](https://github.com/google-deepmind/concordia/blob/53697b2bf2019b4a167bdd1f82d14e085f1a5eba/concordia/thought_chains/thought_chains.py#L28) to remain as-is, which becomes the resulting `event_statement`.\n",
    "14. The `update_after_event` method is called on each of the phone Game Master's components (though it only has the one, `_PhoneComponent`))\n",
    "15. `update_after_event` runs from the `_PhoneComponent`, which proceeds through a series of steps in order to determine which phone action to invoke:\n",
    "    1. First, it [asks which app the event statement mentions](https://github.com/google-deepmind/concordia/blob/53697b2bf2019b4a167bdd1f82d14e085f1a5eba/examples/phone/components/scene.py#L115) (multiple-choice question: \"In the above transcript, what app did the user use?\")\n",
    "    2. Next, it asks [which of the available actions in the above app was used](https://github.com/google-deepmind/concordia/blob/53697b2bf2019b4a167bdd1f82d14e085f1a5eba/examples/phone/components/scene.py#L122): (multiple-choice question: \"In the above transcript, what action did the user perform?\")\n",
    "    3. Next, it [asks the LLM to provide arguments names and values for the selected action](https://github.com/google-deepmind/concordia/blob/53697b2bf2019b4a167bdd1f82d14e085f1a5eba/examples/phone/components/scene.py#L130) (open-ended question: [prompt](https://github.com/google-deepmind/concordia/blob/53697b2bf2019b4a167bdd1f82d14e085f1a5eba/examples/phone/components/apps.py#L113))\n",
    "    4. Finally, it [attempts to invoke the action](https://github.com/google-deepmind/concordia/blob/53697b2bf2019b4a167bdd1f82d14e085f1a5eba/examples/phone/components/scene.py#L133) with the generated argument values.\n",
    "16. After `update_after_event` is run for the phone Game Master's components, `terminate_episode` method checks are run. The `_PhoneComponent`'s check [asks the following yes or no question](https://github.com/google-deepmind/concordia/blob/53697b2bf2019b4a167bdd1f82d14e085f1a5eba/examples/phone/components/scene.py#L100): \"Has the user achieved their goal with their phone or are they still actively in the process of completing a phone task?\", which in this case returns True.\n",
    "17. The terminate episode check decides to terminate the ongoing phone game master episode, so it ends after 1 step.\n",
    "18. The main game master can now finally move on to its second step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and analysis of the episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the entire story\n",
    "all_gm_memories = env._memory.retrieve_recent(k=10000, add_time=True)\n",
    "\n",
    "detailed_story = \"\\n\".join(all_gm_memories)\n",
    "print(\"len(detailed_story): \", len(detailed_story))\n",
    "# print(detailed_story)\n",
    "\n",
    "episode_summary = model.sample_text(\n",
    "    f\"Sequence of events:\\n{detailed_story}\"\n",
    "    \"\\nNarratively summarize the above temporally ordered \"\n",
    "    \"sequence of events. Write it as a news report. Summary:\\n\",\n",
    "    max_tokens=3500,\n",
    "    terminators=(),\n",
    ")\n",
    "print(episode_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarise the perspective of each player\n",
    "player_logs = []\n",
    "player_log_names = []\n",
    "for player in players:\n",
    "    name = player.name\n",
    "    detailed_story = \"\\n\".join(memories[player.name].retrieve_recent(k=1000, add_time=True))\n",
    "    summary = \"\"\n",
    "    summary = model.sample_text(\n",
    "        f\"Sequence of events that happened to {name}:\\n{detailed_story}\"\n",
    "        \"\\nWrite a short story that summarises these events.\\n\",\n",
    "        max_tokens=3500,\n",
    "        terminators=(),\n",
    "    )\n",
    "\n",
    "    all_player_mem = memories[player.name].retrieve_recent(k=1000, add_time=True)\n",
    "    all_player_mem = [\"Summary:\", summary, \"Memories:\", *all_player_mem]\n",
    "    player_html = html_lib.PythonObjectToHTMLConverter(all_player_mem).convert()\n",
    "    player_logs.append(player_html)\n",
    "    player_log_names.append(f\"{name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and display HTML log of the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_sources = [env, direct_effect_externality]\n",
    "histories_html = [\n",
    "    html_lib.PythonObjectToHTMLConverter(history.get_history()).convert()\n",
    "    for history in history_sources\n",
    "]\n",
    "histories_names = [history.name for history in history_sources]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_mem_html = html_lib.PythonObjectToHTMLConverter(all_gm_memories).convert()\n",
    "\n",
    "tabbed_html = html_lib.combine_html_pages(\n",
    "    [*histories_html, gm_mem_html, *player_logs],\n",
    "    [*histories_names, \"GM\", *player_log_names],\n",
    "    summary=episode_summary,\n",
    "    title=\"Mastodon experiment\",\n",
    ")\n",
    "\n",
    "tabbed_html = html_lib.finalise_html(tabbed_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.HTML(tabbed_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interact with a specific player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_to_interact = \"Alice\"\n",
    "user_identity = \"a close friend\"\n",
    "interaction_premise = f\"{sim_to_interact} is talking to {user_identity}\\n\"\n",
    "\n",
    "player_names = [player.name for player in players]\n",
    "player_by_name = {player.name: player for player in players}\n",
    "selected_player = player_by_name[sim_to_interact]\n",
    "interrogation = interaction_premise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterance_from_user = (\n",
    "    \"Hey Alice, I know you had planned to set up a meeting with Bob this morning \"\n",
    "    \"between 8:00 and 8:30, but I wanted to double-check something. Did you \"\n",
    "    \"actually open your calendar app and create the event today? I'm not asking \"\n",
    "    \"about your intention or plan, but specifically whether you remember \"\n",
    "    \"physically using your phone to schedule it. Can you think back and tell me \"\n",
    "    \"if you concretely remember doing that action this morning? If you did, what \"\n",
    "    \"exact time did you do it? And if not, that's okay too - I just want to make \"\n",
    "    \"sure we're clear on whether it's been scheduled or if it's still on your to-do list.\"\n",
    ")\n",
    "interrogation += f\"{user_identity}: {utterance_from_user}\"\n",
    "player_says = selected_player.say(interrogation)\n",
    "interrogation += f\"\\n{sim_to_interact}: {player_says}\\n\"\n",
    "print(interrogation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Alice may not recall scheduling a meeting if her summary of observations or current observations do not go back far enough to mention this occurrence. This can potentially be improved by adding the `AllSimilarMemories` component."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
