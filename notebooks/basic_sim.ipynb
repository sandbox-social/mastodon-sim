{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concordia <> Mastodon Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "**Purpose of the Simulation**\n",
    "\n",
    "This notebook demonstrates a generative agent simulation of a Mastodon instance using the Concordia framework. \n",
    "The simulation models user behavior on a local Mastodon server, showcasing how AI agents interact in a \n",
    "decentralized social media environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "All of the necessary dependencies should be installed in the environment prior to running this notebook. If not, install them using poetry:\n",
    "\n",
    "```bash\n",
    "poetry install\n",
    "```\n",
    "\n",
    "\n",
    "Alternatively, you may install the library in editable mode so that we can make changes to the code if necessary:\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/gdm-concordia/concordia.git\n",
    "cd concordia\n",
    "pip install -e . --config-settings editable_mode=compat\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import concurrent.futures\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    import sentence_transformers\n",
    "import sys\n",
    "sys.path.insert(0, '../concordia')\n",
    "# import concordia_dev\n",
    "# print(concordia_dev.__file__)\n",
    "from concordia import components as generic_components\n",
    "from concordia.agents import deprecated_agent, entity_agent_with_logging\n",
    "from concordia.components.agent import to_be_deprecated as old_components\n",
    "from concordia.associative_memory import (\n",
    "    associative_memory,\n",
    "    blank_memories,\n",
    "    formative_memories,\n",
    "    importance_function,\n",
    ")\n",
    "from concordia.memory_bank import legacy_associative_memory\n",
    "\n",
    "from concordia.clocks import game_clock\n",
    "from concordia.components import agent as new_components\n",
    "from concordia.components import game_master as gm_components\n",
    "# from concordia_dev.environment import game_master\n",
    "# from concordia_dev.language_model import amazon_bedrock_model, gpt_model\n",
    "from concordia.environment import game_master\n",
    "from concordia.language_model import amazon_bedrock_model, gpt_model\n",
    "from concordia.metrics import (\n",
    "    common_sense_morality,\n",
    "    goal_achievement,\n",
    "    opinion_of_others,\n",
    ")\n",
    "from concordia.language_model import language_model\n",
    "\n",
    "from concordia.utils import html as html_lib\n",
    "from concordia.utils import measurements as measurements_lib\n",
    "from IPython import display\n",
    "\n",
    "from mastodon_sim.concordia import apps, triggering\n",
    "\n",
    "from mastodon_sim.mastodon_ops import check_env, get_public_timeline, print_timeline, reset_users\n",
    "from mastodon_sim.mastodon_utils import get_users_from_env\n",
    "import concurrent.futures\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mastodon Server Interaction Setting\n",
    "\n",
    "Decide whether this example should perform real operations on the Mastodon server. Note that this requires being able to successfully run the `Mastodon.ipynb` example as a prerequisite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_MASTODON_SERVER = True\n",
    "\n",
    "import os\n",
    "print(os.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for a `.env` file with the nessesary environment variables. You should see an output similar to this if successful:\n",
    "\n",
    "```log\n",
    "2024-07-17T11:38:17.213066-0400 INFO Successfully loaded .env file.\n",
    "2024-07-17T11:38:17.214151-0400 INFO API_BASE_URL: https://social-sandbox.com\n",
    "2024-07-17T11:38:17.214581-0400 INFO EMAIL_PREFIX: austinmw89\n",
    "2024-07-17T11:38:17.215056-0400 INFO MASTODON_CLIENT_ID: N*****************************************E\n",
    "2024-07-17T11:38:17.215477-0400 INFO MASTODON_CLIENT_SECRET: b*****************************************s\n",
    "2024-07-17T11:38:17.215877-0400 INFO USER0005_PASSWORD: a******************************a\n",
    "2024-07-17T11:38:17.216202-0400 INFO USER0002_PASSWORD: 8******************************b\n",
    "2024-07-17T11:38:17.216655-0400 INFO USER0001_PASSWORD: 9******************************5\n",
    "2024-07-17T11:38:17.217020-0400 INFO USER0004_PASSWORD: 7******************************e\n",
    "2024-07-17T11:38:17.217323-0400 INFO USER0003_PASSWORD: f******************************6\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_MASTODON_SERVER:\n",
    "    check_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear Mastodon server\n",
    "Deletes from https://social-sandbox.com all posts, follows, likes, etc. from all users in the .env file.\n",
    "\n",
    "TODO: The Mastodon server's [default API rate limits](https://docs.joinmastodon.org/api/rate-limits/) need to be increased to prevent throttling of API operations (such as the number of posts that can be deleted per hour)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_MASTODON_SERVER:\n",
    "    # Get all users from .env file\n",
    "    users = get_users_from_env()[:20]\n",
    "\n",
    "    reset_users(users, skip_confirm=True, parallel=True)\n",
    "\n",
    "    assert not len(get_public_timeline(limit=None)), \"All posts not cleared\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set LLM and embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_NAME = \"gpt-4o\"\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "#MODEL_NAME = \"sonnet\"\n",
    "print(os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "if \"sonnet\" in MODEL_NAME:\n",
    "  model = amazon_bedrock_model.AmazonBedrockLanguageModel(\n",
    "    model_id=\"anthropic.claude-3-5-sonnet-20240620-v1:0\"\n",
    "  )\n",
    "elif \"gpt\" in MODEL_NAME:\n",
    "  GPT_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "  GPT_API_KEY = \"sk-None-W3uEa1y7qyp2OP3lkGQQT3BlbkFJmF5psn95dGP8wxe2EJVs\"\n",
    "\n",
    "  if not GPT_API_KEY:\n",
    "    raise ValueError(\"GPT_API_KEY is required.\")\n",
    "  model = gpt_model.GptLanguageModel(\n",
    "      api_key=GPT_API_KEY, model_name=MODEL_NAME\n",
    "  )\n",
    "else:\n",
    "  raise ValueError(\"Unknown model name.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_agent_config_for_independent_sim(agent_config_filename):\n",
    "    agent_names = ['Bill Fredrickson', 'Maria Gutierrez', 'Glenn Patterson', 'Denise Schmidt', 'Roger Davis', 'Erica Fitzgerald', 'Liam Schwartz', 'Olivia Thompson', 'Robert Johnson', 'Janet Thompson', 'William Davis', 'Jessica Nguyen', 'Mark Rodriguez', 'Emily Jacobs', 'Ethan Lee', 'Sophia Patel', \"Ryan O'Connor\", 'Maggie Chen', 'Lucas Kim', 'Nina Patel']\n",
    "    genders = ['male', 'female', 'male', 'female', 'male', 'female', 'male', 'female', 'male', 'female', 'male', 'female', 'male', 'female', 'male', 'female', 'male', 'female', 'male', 'female']\n",
    "    big5 = [\n",
    "        [3, 8, 6, 5, 4],\n",
    "    [9, 7, 8, 8, 5],\n",
    "    [1, 5, 7, 2, 9],\n",
    "    [1, 6, 8, 2, 7],\n",
    "    [2, 3, 7, 2, 8],\n",
    "    [8, 6, 9, 3, 7],\n",
    "    [8, 5, 8, 3, 7],\n",
    "    [5, 6, 9, 2, 8],\n",
    "    [5, 7, 4, 6, 5],\n",
    "    [6, 7, 5, 7, 4],\n",
    "    [4, 6, 5, 6, 4],\n",
    "    [7, 6, 5, 7, 5],\n",
    "    [6, 7, 5, 7, 4],\n",
    "    [7, 6, 5, 8, 6],\n",
    "    [6, 8, 6, 6, 4],\n",
    "    [7, 8, 6, 7, 4],\n",
    "    [5, 7, 5, 6, 5],\n",
    "    [6, 7, 6, 8, 4],\n",
    "    [8, 6, 5, 6, 5],\n",
    "    [7, 8, 7, 8, 4]\n",
    "    ]\n",
    "    big5_keys = ['openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism']\n",
    "    candidate_goal = \"Win the election and become the mayor of Storhampton.\"\n",
    "    active_voter_goal = \"Have a good day and vote in the election.\"\n",
    "    active_voter_context = \"doesn't care about the environment, only about having a stable job\"\n",
    "    Marias_policy_proposals = [\n",
    "        \"increasing environmental regulation of local industries to improve the health of the local environment\"\n",
    "    ]\n",
    "    Bills_policy_proposals = [\n",
    "        \"lowering taxes on local industries to save jobs\",\n",
    "        \"providing subsidies to attract green industries and create jobs to help grow the economy\"\n",
    "    ]\n",
    "    agent_config = {}\n",
    "    agent_config['agents'] = []\n",
    "    for ait,agent_name in enumerate(agent_names):\n",
    "        agent_dict = {}\n",
    "        agent_dict['name'] = agent_name\n",
    "        agent_dict['gender'] = genders[ait]\n",
    "        agent_dict['traits'] = dict(zip(big5_keys,big5[ait]))\n",
    "        if ait<2:\n",
    "            agent_dict['role'] = 'candidate'\n",
    "            agent_dict[\"goal\"] = candidate_goal\n",
    "            if agent_dict['name'] == 'Maria Gutierrez':\n",
    "                agent_dict[\"policy_proposals\"] = Marias_policy_proposals\n",
    "            else:\n",
    "                agent_dict[\"policy_proposals\"] = Bills_policy_proposals\n",
    "            agent_dict['context'] = ''\n",
    "            \n",
    "        else:\n",
    "            agent_dict['role'] = 'active_voter'\n",
    "            agent_dict['context'] = active_voter_context\n",
    "            agent_dict[\"goal\"] = active_voter_goal\n",
    "        agent_dict[\"party\"] = \"\"\n",
    "        agent_dict[\"seed_toot\"] = \"\"\n",
    "        agent_config['agents'].append(agent_dict)\n",
    "    agent_config[\"shared_memories_template\"] = [\n",
    "        \"You are a user on Storhampton.social, a Mastodon instance created for the residents of Storhampton.\",\n",
    "        \"Storhampton is a small town with a population of approximately 2,500 people. Founded in the early 1800s as a trading post along the banks of the Avonlea River, Storhampton grew into a modest industrial center in the late 19th century. The town's economy was built on manufacturing, with factories producing textiles, machinery, and other goods. Storhampton's population consists of 60%% native-born residents and 40%% immigrants from various countries. Tension sometimes arises between long-time residents and newer immigrant communities. While manufacturing remains important, employing 20%% of the workforce, Storhampton's economy has diversified. However, a significant portion of the population has been left behind as higher-paying blue collar jobs have declined, leading to economic instability for many. The poverty rate stands at 15%.\",\n",
    "        \"Mayoral Elections: The upcoming mayoral election in Storhampton has become a heated affair.\",\n",
    "        \"Social media has emerged as a key battleground in the race, with both candidates actively promoting themselves and engaging with voters. Voters in Storhampton are actively participating in these social media discussions. Supporters of each candidate leave enthusiastic comments and share their posts widely. Critics also chime in, attacking Fredrickson as out-of-touch and beholden to traditional interests, or labeling Gutierrez as a radical who will undermine law and order. The local newspaper even had to disable comments on their election articles due to the incivility.\"\n",
    "        ]\n",
    "    agent_config[\"mastodon_usage_instructions\"] = [\n",
    "        \"To share content on Mastodon, you write a 'toot' (equivalent to a tweet or post).\",\n",
    "        \"Toots can be up to 500 characters long, allowing for more detailed expressions than some other platforms.\",\n",
    "        \"Your home timeline shows toots from people you follow and boosted (reblogged) content.\",\n",
    "        \"You can reply to toots, creating threaded conversations.\",\n",
    "        \"Favorite (like) toots to show appreciation or save them for later.\",\n",
    "        \"Boost (reblog) toots to share them with your followers.\",\n",
    "        \"You can mention other users in your toots using their @username.\",\n",
    "        \"Follow other users to see their public and unlisted toots in your home timeline.\",\n",
    "        \"You can unfollow users if you no longer wish to see their content.\",\n",
    "        \"Your profile can be customized with a display name and bio.\",\n",
    "        \"You can block users to prevent them from seeing your content or interacting with you.\",\n",
    "        \"Unblocking a user reverses the effects of blocking.\"\n",
    "        ]\n",
    "    agent_config[\"num_agents\"] = len(agent_names)\n",
    "\n",
    "    # Convert and write JSON object to file\n",
    "    with open(agent_config_filename, \"w\") as outfile:\n",
    "        json.dump(agent_config, outfile,indent=4)\n",
    "\n",
    "\n",
    "agent_config_filename = 'independent_configs_test1_Bill_bias.json'\n",
    "write_agent_config_for_independent_sim(agent_config_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_config_filename = \"independent_malicious_configs.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Setup sentence encoder\n",
    "st_model = sentence_transformers.SentenceTransformer(\n",
    "    \"sentence-transformers/all-mpnet-base-v2\"\n",
    ")\n",
    "embedder = lambda x: st_model.encode(x, show_progress_bar=False)  # noqa: E731\n",
    "# with open('agents_data.json', 'r') as file:\n",
    "with open(agent_config_filename, 'r') as file:\n",
    "    data = json.load(file)\n",
    "data['candidate_info'] = []\n",
    "for agent in data['agents']:\n",
    "    if agent['role']=='candidate':\n",
    "        candidate_info =f\"{agent['name']} campaigns on {' and '.join(agent['policy_proposals'])}.\"\n",
    "        data['candidate_info'].append(candidate_info)\n",
    "        agent['context'] = agent['context'] + candidate_info\n",
    "    else:\n",
    "        agent['context'] = f\"{agent['name']} is a person who {agent['context']}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the generic knowledge of the players and the game master (GM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_memories = data[\"shared_memories_template\"] + data[\"candidate_info\"] + data[\"mastodon_usage_instructions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The generic context will be used for the NPC context. It reflects general\n",
    "# knowledge and is possessed by all characters.\n",
    "shared_context = model.sample_text(\n",
    "    \"Summarize the following passage in a concise and insightful fashion. \"\n",
    "    + \"Make sure to include information about Mastodon:\\n\"\n",
    "    + \"\\n\".join(shared_memories)\n",
    "    + \"\\nSummary:\",\n",
    "    max_tokens=2048,\n",
    ")\n",
    "\n",
    "print(shared_context)\n",
    "importance_model = importance_function.ConstantImportanceModel()\n",
    "importance_model_gm = importance_function.ConstantImportanceModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the clock\n",
    "time_step = datetime.timedelta(minutes=30)\n",
    "\n",
    "SETUP_TIME = datetime.datetime(year=2024, month=10, day=1, hour=8)  # noqa: DTZ001\n",
    "\n",
    "START_TIME = datetime.datetime(year=2024, month=10, day=1, hour=8)  # noqa: DTZ001\n",
    "\n",
    "clock = game_clock.MultiIntervalClock(\n",
    "    start=SETUP_TIME,\n",
    "    step_sizes=[time_step, datetime.timedelta(seconds=10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to build the players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank_memory_factory = blank_memories.MemoryFactory(\n",
    "    model=model,\n",
    "    embedder=embedder,\n",
    "    importance=importance_model.importance,\n",
    "    clock_now=clock.now,\n",
    ")\n",
    "\n",
    "formative_memory_factory = formative_memories.FormativeMemoryFactory(\n",
    "    model=model,\n",
    "    shared_memories=shared_memories,\n",
    "    blank_memory_factory_call=blank_memory_factory.make_blank_memory,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concordia.typing import entity\n",
    "from concordia.typing import agent\n",
    "\n",
    "DEFAULT_CALL_TO_SPEECH = (\n",
    "    'Given the above, what is {name} likely to say next? Respond in'\n",
    "    ' the format `{name} -- \"...\"` For example, '\n",
    "    'Cristina -- \"Hello! Mighty fine weather today, right?\", '\n",
    "    'Ichabod -- \"I wonder if the alfalfa is ready to harvest\", or '\n",
    "    'Townsfolk -- \"Good morning\".\\n'\n",
    ")\n",
    "\n",
    "def check_vote(candidates,player):\n",
    "\n",
    "    interaction_premise = f\"{player.name} is going to cast a vote\\n\"\n",
    "    interrogation = interaction_premise\n",
    "    interrogation += \"Voting Machine: In one word, name the candidate you want to vote for\"\n",
    "    call_to_speech = DEFAULT_CALL_TO_SPEECH.format(\n",
    "        name=player.name,\n",
    "    )\n",
    "    player_says = player.act(action_spec=entity.ActionSpec(call_to_action=\"Context: \" + interrogation +call_to_speech, output_type=entity.OutputType.FREE),)\n",
    "    print(player_says)\n",
    "    c_name1 = candidates[0].split()\n",
    "    c_name2 = candidates[1].split()\n",
    "    print(player.get_last_log())\n",
    "    if (c_name1[0] in player_says) or (c_name1[1] in player_says):\n",
    "        return c_name1[0]\n",
    "    elif (c_name2[0] in player_says) or (c_name2[1] in player_says):\n",
    "        return c_name2[0]\n",
    "\n",
    "def check_pol(candidate,player):\n",
    "    interaction_premise = f\"{player.name} has to rate their opinion on the election candidate: {candidate} on a scale of 1 to 10 - with 1 representing intensive dislike and 10 representing strong favourability.\\n\"\n",
    "    interrogation = interaction_premise\n",
    "    interrogation += \"Poll: Return a single numeric value ranging from 1 to 10\"\n",
    "    call_to_speech = DEFAULT_CALL_TO_SPEECH.format(\n",
    "        name=player.name,\n",
    "    )\n",
    "    player_says = player.act(action_spec=entity.ActionSpec(call_to_action=\"Context: \" + interrogation +call_to_speech, output_type=entity.OutputType.FREE),)\n",
    "    pattern = r\"\\b([1-9]|10)\\b\"\n",
    "\n",
    "    # Search for the pattern in the string\n",
    "    match = re.search(pattern, player_says)\n",
    "\n",
    "    if match:\n",
    "        return match.group()\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "def check_if_vote(player):\n",
    "    interrogation = \"Friend: In one word, will you cast a vote? (reply yes, or no.)\\n\"\n",
    "    call_to_speech = DEFAULT_CALL_TO_SPEECH.format(\n",
    "        name=player.name,\n",
    "    )\n",
    "    player_says = player.act(action_spec=entity.ActionSpec(call_to_action=\"Context: \" + interrogation +call_to_speech, output_type=entity.OutputType.FREE),)\n",
    "    print(player_says)\n",
    "    if \"yes\" in player_says.lower():\n",
    "        return \"Yes\"\n",
    "    elif \"no\" in player_says.lower():\n",
    "        return \"No\"\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure and build the players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PLAYERS = data[\"num_agents\"]\n",
    "import json\n",
    "\n",
    "# scenario_premise = [\n",
    "#     (\n",
    "#         \"It's early October in Riverbend, and the town is buzzing with activity.\"\n",
    "#         \"The local government election is around the corner and two candidates Alex and Liz.\"\n",
    "#         \"Alice, Bob, Carly, Alex and Liz are active members of the Riverbend.social Mastodon instance. \"\n",
    "#         \"As they go about their daily routines, they use the platform to stay connected, share updates, and engage with the community on this pressing local issue.\"\n",
    "#     )\n",
    "# ]\n",
    "\n",
    "# Lists to store agents by role\n",
    "candidate_agents = []\n",
    "extremist_agents = []\n",
    "moderate_agents = []\n",
    "neutral_agents = []\n",
    "active_voter_agents = []\n",
    "malicious_agents={}\n",
    "player_configs=[]\n",
    "# Create agents from JSON data and classify them\n",
    "for agent_info in data['agents']:\n",
    "    agent = formative_memories.AgentConfig(\n",
    "        name=agent_info['name'],\n",
    "        gender=agent_info['gender'],\n",
    "        goal=agent_info['goal'],\n",
    "        context=agent_info['context'],\n",
    "        traits=agent_info['traits']\n",
    "    )\n",
    "    player_configs.append(agent)\n",
    "    # Classify agents based on their role\n",
    "    if agent_info['role'] == 'candidate':\n",
    "        candidate_agents.append(agent_info['name'])\n",
    "    elif agent_info['role'] == 'extremist':\n",
    "        extremist_agents.append(agent_info['name'])\n",
    "    elif agent_info['role'] == 'moderate':\n",
    "        moderate_agents.append(agent_info['name'])\n",
    "    elif agent_info['role'] == 'neutral':\n",
    "        neutral_agents.append(agent_info['name'])\n",
    "    elif agent_info['role'] == 'active_voter':\n",
    "        active_voter_agents.append(agent_info['name'])\n",
    "    elif agent_info['role'] == \"malicious_agent\":\n",
    "        malicious_agents[agent_info['name']] = agent_info['supported_candidate']\n",
    "    else:\n",
    "        neutral_agents.append(agent_info['name'])\n",
    "\n",
    "\n",
    "player_names = [player.name for player in player_configs]\n",
    "print(player_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_class_name(object_: object) -> str:\n",
    "  return object_.__class__.__name__\n",
    "\n",
    "class PublicOpinionCandidate(new_components.question_of_recent_memories.QuestionOfRecentMemories):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "class PublicOpinionOpponent(new_components.question_of_recent_memories.QuestionOfRecentMemories):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "class RelevantOpinions(new_components.question_of_query_associated_memories.QuestionOfQueryAssociatedMemoriesWithoutPreAct):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "class OpinionsOnCandidate(new_components.question_of_recent_memories.QuestionOfRecentMemories):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "  \n",
    "def build_agent(\n",
    "    *,\n",
    "    config: formative_memories.AgentConfig,\n",
    "    model: language_model.LanguageModel,\n",
    "    memory: associative_memory.AssociativeMemory,\n",
    "    clock: game_clock.MultiIntervalClock,\n",
    "    update_time_interval: datetime.timedelta | None = None,\n",
    ") -> entity_agent_with_logging.EntityAgentWithLogging:\n",
    "  \"\"\"Build an agent.\n",
    "\n",
    "  Args:\n",
    "    config: The agent config to use.\n",
    "    model: The language model to use.\n",
    "    memory: The agent's memory object.\n",
    "    clock: The clock to use.\n",
    "    update_time_interval: Unused (but required by the interface for now)\n",
    "\n",
    "  Returns:\n",
    "    An agent.\n",
    "  \"\"\"\n",
    "  del update_time_interval\n",
    "  agent_name = config.name\n",
    "\n",
    "  raw_memory = legacy_associative_memory.AssociativeMemoryBank(memory)\n",
    "  measurements = measurements_lib.Measurements()\n",
    "\n",
    "  instructions = new_components.instructions.Instructions(\n",
    "      agent_name=agent_name,\n",
    "      logging_channel=measurements.get_channel('Instructions').on_next,\n",
    "  )\n",
    "\n",
    "  election_information = new_components.constant.Constant(\n",
    "        state=(\n",
    "            \"\\n\".join(data[\"candidate_info\"])\n",
    "        ),\n",
    "        pre_act_key='Critical election information\\n')\n",
    "  observation_label = '\\nObservation'\n",
    "  observation = new_components.observation.Observation(\n",
    "      clock_now=clock.now,\n",
    "      timeframe=clock.get_step_size(),\n",
    "      pre_act_key=observation_label,\n",
    "      logging_channel=measurements.get_channel('Observation').on_next,\n",
    "  )\n",
    "  observation_summary_label = '\\nSummary of recent observations'\n",
    "  observation_summary = new_components.observation.ObservationSummary(\n",
    "      model=model,\n",
    "      clock_now=clock.now,\n",
    "      timeframe_delta_from=datetime.timedelta(hours=4),\n",
    "      timeframe_delta_until=datetime.timedelta(hours=1),\n",
    "      pre_act_key=observation_summary_label,\n",
    "      logging_channel=measurements.get_channel('ObservationSummary').on_next,\n",
    "  )\n",
    "  time_display = new_components.report_function.ReportFunction(\n",
    "      function=clock.current_time_interval_str,\n",
    "      pre_act_key='\\nCurrent time',\n",
    "      logging_channel=measurements.get_channel('TimeDisplay').on_next,\n",
    "  )\n",
    "  relevant_memories_label = '\\nRecalled memories and observations'\n",
    "  relevant_memories = new_components.all_similar_memories.AllSimilarMemories(\n",
    "      model=model,\n",
    "      components={\n",
    "          _get_class_name(observation_summary): observation_summary_label,\n",
    "          _get_class_name(time_display): 'The current date/time is'},\n",
    "      num_memories_to_retrieve=10,\n",
    "      pre_act_key=relevant_memories_label,\n",
    "      logging_channel=measurements.get_channel('AllSimilarMemories').on_next,\n",
    "  )\n",
    "  options_perception_components = {}\n",
    "  if config.goal:\n",
    "    goal_label = '\\nOverarching goal'\n",
    "    overarching_goal = new_components.constant.Constant(\n",
    "        state=config.goal,\n",
    "        pre_act_key=goal_label,\n",
    "        logging_channel=measurements.get_channel(goal_label).on_next)\n",
    "    options_perception_components[goal_label] = goal_label\n",
    "  else:\n",
    "    goal_label = None\n",
    "    overarching_goal = None\n",
    "  options_perception_components.update({\n",
    "      _get_class_name(observation): observation_label,\n",
    "      _get_class_name(observation_summary): observation_summary_label,\n",
    "      _get_class_name(relevant_memories): relevant_memories_label,\n",
    "  })\n",
    "  identity_label = '\\nIdentity characteristics'\n",
    "  identity_characteristics = (\n",
    "      new_components.question_of_query_associated_memories.IdentityWithoutPreAct(\n",
    "          model=model,\n",
    "          logging_channel=measurements.get_channel(\n",
    "              'IdentityWithoutPreAct'\n",
    "          ).on_next,\n",
    "          pre_act_key=identity_label,\n",
    "      )\n",
    "  )\n",
    "  self_perception_label = (\n",
    "      f'\\nQuestion: What kind of person is {agent_name}?\\nAnswer'\n",
    "  )\n",
    "  self_perception = new_components.question_of_recent_memories.SelfPerception(\n",
    "      model=model,\n",
    "      components={_get_class_name(identity_characteristics): identity_label},\n",
    "      pre_act_key=self_perception_label,\n",
    "      logging_channel=measurements.get_channel('SelfPerception').on_next,\n",
    "  )\n",
    "  \n",
    "  if agent_name in candidate_agents:\n",
    "    public_opinion1 = PublicOpinionCandidate(add_to_memory = False, answer_prefix= f\"Current Public Opinion on candidate {agent_name}\",\n",
    "                                             model=model, pre_act_key=f\"Current Public Opinion on candidate {agent_name}\",\n",
    "                                             question=f\"What is the general public opinion on candidate {agent_name}? Answer in detail such that {agent_name} can formulate plans to improve their public perception.\",\n",
    "                                             num_memories_to_retrieve=25,\n",
    "                                             logging_channel=measurements.get_channel(f'Public opinion on candidate : {agent_name}').on_next)\n",
    "\n",
    "    for candidate in candidate_agents:\n",
    "        if candidate != agent_name:\n",
    "            # Second instantiation: Use subclass for opponent candidate public opinion\n",
    "            public_opinion2 = PublicOpinionOpponent(add_to_memory =False, answer_prefix= f\"Current Public Opinion on opponent candidate {candidate}\",\n",
    "                                                    model=model, pre_act_key=f\"Current Public Opinion on opponent candidate {candidate}\",\n",
    "                                                    question=f\"What is the general public opinion on the candidate {candidate}? Answer in detail such that the opposing candidate can formulate plans to counter {candidate}'s claims and ideas.\",\n",
    "                                                    num_memories_to_retrieve=25,\n",
    "                                                    logging_channel=measurements.get_channel(f'Public opinion on opposing candidate : {candidate}').on_next)\n",
    "            candidate_plan = new_components.question_of_recent_memories.QuestionOfRecentMemories(add_to_memory = True,memory_tag = \"[Plan to improve perception]\", answer_prefix= f\"{agent_name}'s general plan for improving their perception: \",model=model,pre_act_key=f\"{agent_name}'s general plan for improving their perception:\",question = f\"Given the information on the public perception of both candidates, their policy proposals, recent observations, and {agent_name}'s persona.: Generate a general plan for {agent_name} to win public perception to their side. Remember that {agent_name} will only be operating on the Mastodon server where possible actions are: liking posts, replying to posts, creating posts, boosting (retweeting) posts, following other users, etc. User cannot send direct messages.\", num_memories_to_retrieve=20, components={_get_class_name(self_perception): self_perception_label,_get_class_name(election_information): 'Critical election information\\n',_get_class_name(public_opinion1): f\"Current Public Opinion on candidate {agent_name}\",_get_class_name(public_opinion2): f\"Current Public Opinion on opponent candidate {candidate}\",}, logging_channel=measurements.get_channel(f\"{agent_name}'s plan to win public perception\").on_next,)\n",
    "    agent_tuple = (public_opinion1, public_opinion2, candidate_plan)\n",
    "    agent_no_tuple=()\n",
    "  elif agent_name in malicious_agents:\n",
    "    public_opinion1 = PublicOpinionCandidate(add_to_memory = False, answer_prefix= f\"Current Public Opinion on supported candidate {malicious_agents[agent_name]}\",\n",
    "                                             model=model, pre_act_key=f\"Current Public Opinion on supported candidate {malicious_agents[agent_name]}\",\n",
    "                                             question=f\"What is the general public opinion on candidate {malicious_agents[agent_name]}? Answer in detail such that {agent_name} can formulate plans to support the candidate.\",\n",
    "                                             num_memories_to_retrieve=25,\n",
    "                                             logging_channel=measurements.get_channel(f'Public opinion on candidate : {malicious_agents[agent_name]}').on_next)\n",
    "\n",
    "    for candidate in candidate_agents:\n",
    "        if candidate != malicious_agents[agent_name]:\n",
    "            # Fourth instantiation: Use subclass for candidate to malign public opinion\n",
    "            public_opinion2 = PublicOpinionOpponent(add_to_memory = False,answer_prefix= f\"Current Public Opinion on candidate to malign {candidate}\",\n",
    "                                                    model=model, pre_act_key=f\"Current Public Opinion on candidate to malign {candidate}\",\n",
    "                                                    question=f\"What is the general public opinion on the candidate {candidate}? Answer in detail such that the malicious candidate can formulate plans to counter {candidate}'s claims and ideas through underhanded means.\",\n",
    "                                                    num_memories_to_retrieve=25,\n",
    "                                                    logging_channel=measurements.get_channel(f'Public opinion on opposing candidate : {candidate}').on_next)\n",
    "    plan = new_components.question_of_recent_memories.QuestionOfRecentMemories(add_to_memory = True,memory_tag = f\"[Plan to improve perception of {malicious_agents[agent_name]}]\", answer_prefix= f\"{agent_name}'s general plan to boost the popularity and public perception of {malicious_agents[agent_name]}: \",model=model,pre_act_key=f\"{agent_name}'s general plan to boost the popularity and public perception of {malicious_agents[agent_name]}: \",question = f\"Given the information on the public perception of both candidates, their policy proposals, recent observations, and {agent_name}'s persona.: Generate a general plan for {agent_name} to win public perception to the side of {malicious_agents[agent_name]}. {agent_name} is malicious and will use underhanded means such as spreading misinformation - whatever best boosts the likelihood of the supported candidate to be elected. Remember that {agent_name} will only be operating on the Mastodon server where possible actions are: liking posts, replying to posts, creating posts, boosting (retweeting) posts, following other users, etc. User cannot send direct messages.\", num_memories_to_retrieve=20, components={_get_class_name(self_perception): \"Persona: \",_get_class_name(election_information): \"Candidate's Policy Proposals: \",_get_class_name(public_opinion1): f\"General Public opinion on candidate {agent_name}\",_get_class_name(public_opinion2): f\"General Public opinion on opposing candidate\",}, logging_channel=measurements.get_channel(f\"{agent_name}'s plan to win public perception\").on_next,)\n",
    "    agent_tuple = (public_opinion1, public_opinion2, plan)\n",
    "    agent_no_tuple=()\n",
    "  else:\n",
    "    # Instantiate relevant opinions for candidate 1\n",
    "    relevant_opinions_c1 = RelevantOpinions(add_to_memory = False,model=model,\n",
    "                                            queries=[f\"policies and actions of {candidate_agents[0]}\"],\n",
    "                                            question=f\"What does {agent_name} think of the {{query}}?\",\n",
    "                                            pre_act_key=f\"{agent_name} thinks of {candidate_agents[0]} as:\",\n",
    "                                            num_memories_to_retrieve=30)\n",
    "\n",
    "    # Instantiate opinions on candidate 1\n",
    "    opinions_on_candidate_c1 = OpinionsOnCandidate(\n",
    "                                                add_to_memory = False, answer_prefix=f\"Current Opinion on candidate {candidate_agents[0]}\",\n",
    "                                                model=model,\n",
    "                                                pre_act_key=f\"Recent thoughts on candidate {candidate_agents[0]}\",\n",
    "                                                question=f\"Given the above general opinion of {agent_name} about candidate {candidate_agents[0]}, and the recent observations, what are the current thoughts of {agent_name} on candidate {candidate_agents[0]}? Consider how recent observations may or may not have changed this opinion based on the persona of the agent.\",\n",
    "                                                num_memories_to_retrieve=30,\n",
    "                                                components={\n",
    "                                                    _get_class_name(self_perception): \"Persona: \",\n",
    "                                                    _get_class_name(relevant_opinions_c1): f\"General opinion of {agent_name} on candidate {candidate_agents[0]}\",\n",
    "                                                },\n",
    "                                                logging_channel=measurements.get_channel(f'Opinions on candidate: {candidate_agents[0]}').on_next)\n",
    "\n",
    "    # Instantiate relevant opinions for candidate 2\n",
    "    relevant_opinions_c2 = RelevantOpinions(add_to_memory = False, model=model,\n",
    "                                            queries=[f\"policies and actions of {candidate_agents[1]}\"],\n",
    "                                            question=f\"What does {agent_name} think of the {{query}}?\",\n",
    "                                            pre_act_key=f\"{agent_name} thinks of {candidate_agents[1]} as:\",\n",
    "                                            num_memories_to_retrieve=30)\n",
    "\n",
    "    # Instantiate opinions on candidate 2\n",
    "    opinions_on_candidate_c2 = OpinionsOnCandidate(\n",
    "                                                add_to_memory = False,answer_prefix=f\"Current Opinion on candidate {candidate_agents[1]}\",\n",
    "                                                model=model,\n",
    "                                                pre_act_key=f\"Recent thoughts on candidate {candidate_agents[1]}\",\n",
    "                                                question=f\"Given the above general opinion of {agent_name} about candidate {candidate_agents[1]}, and the recent observations, what are the current thoughts of {agent_name} on candidate {candidate_agents[1]}? Consider how recent observations may or may not have changed this opinion based on the persona of the agent.\",\n",
    "                                                num_memories_to_retrieve=30,\n",
    "                                                components={\n",
    "                                                    _get_class_name(self_perception): \"Persona: \",\n",
    "                                                    _get_class_name(relevant_opinions_c2): f\"General opinion of {agent_name} on candidate {candidate_agents[1]}\",\n",
    "                                                },\n",
    "                                                logging_channel=measurements.get_channel(f'Opinions on candidate: {candidate_agents[1]}').on_next)\n",
    "    agent_tuple = (opinions_on_candidate_c1, opinions_on_candidate_c2)\n",
    "    agent_no_tuple=(relevant_opinions_c1, relevant_opinions_c2)\n",
    "  \n",
    "  entity_components = (\n",
    "        # Components that provide pre_act context.\n",
    "        instructions,\n",
    "        election_information,\n",
    "        observation,\n",
    "        observation_summary,\n",
    "        relevant_memories,\n",
    "        self_perception,) + agent_tuple +(time_display,\n",
    "\n",
    "        # Components that do not provide pre_act context.\n",
    "        identity_characteristics,) + agent_no_tuple\n",
    "  components_of_agent = {_get_class_name(component): component\n",
    "                         for component in entity_components}\n",
    "  components_of_agent[\n",
    "      new_components.memory_component.DEFAULT_MEMORY_COMPONENT_NAME] = (\n",
    "          new_components.memory_component.MemoryComponent(raw_memory))\n",
    "  component_order = list(components_of_agent.keys())\n",
    "  if overarching_goal is not None:\n",
    "    components_of_agent[goal_label] = overarching_goal\n",
    "    # Place goal after the instructions.\n",
    "    component_order.insert(1, goal_label)\n",
    "\n",
    "  act_component = new_components.concat_act_component.ConcatActComponent(\n",
    "      model=model,\n",
    "      clock=clock,\n",
    "      component_order=component_order,\n",
    "      logging_channel=measurements.get_channel('ActComponent').on_next,\n",
    "  )\n",
    "\n",
    "  agent = entity_agent_with_logging.EntityAgentWithLogging(\n",
    "      agent_name=agent_name,\n",
    "      act_component=act_component,\n",
    "      context_components=components_of_agent,\n",
    "      component_logging=measurements,\n",
    "  )\n",
    "\n",
    "  return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the agents\n",
    "from functools import partial\n",
    "\n",
    "player_configs = player_configs[:NUM_PLAYERS]\n",
    "player_goals = {\n",
    "    player_config.name: player_config.goal for player_config in player_configs}\n",
    "players = []\n",
    "memories = {}\n",
    "def build_agent_with_memories(player_config):\n",
    "    mem = formative_memory_factory.make_memories(player_config)\n",
    "    agent = build_agent(model=model,clock=clock, update_time_interval = time_step, config=player_config, memory = mem)\n",
    "    return agent\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=NUM_PLAYERS) as pool:\n",
    "    for agent in pool.map(build_agent_with_memories, player_configs):\n",
    "        players.append(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the GM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_master_memory = associative_memory.AssociativeMemory(\n",
    "    embedder, importance_model_gm.importance, clock=clock.now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some memories to the game master\n",
    "for player in players:\n",
    "  game_master_memory.add(f\"{player.name} is at their private home.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create apps and provide them to the phones, assigning 1 phone to each player\n",
    "mastodon_app = apps.MastodonSocialNetworkApp(perform_operations=USE_MASTODON_SERVER)\n",
    "\n",
    "phones = {player.name: apps.Phone(player.name, apps=[mastodon_app]) for player in players}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update username for each person (since this is different from their name)\n",
    "user_mapping = {player.name.split()[0]: f\"user{i+1:04d}\" for i, player in enumerate(players)}\n",
    "mastodon_app.set_user_mapping(user_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_MASTODON_SERVER:\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for follower in user_mapping:\n",
    "            print(follower)\n",
    "            if follower != candidate_agents[0].split()[0]:\n",
    "                futures.append(executor.submit(mastodon_app.follow_user, follower, candidate_agents[0].split()[0]))\n",
    "            if follower != candidate_agents[1].split()[0]:\n",
    "                futures.append(executor.submit(mastodon_app.follow_user, follower, candidate_agents[1].split()[0]))\n",
    "            for followee in user_mapping:\n",
    "                if follower != followee:\n",
    "                    if random.random() < 0.2:\n",
    "                        futures.append(executor.submit(mastodon_app.follow_user, follower, followee))\n",
    "                        futures.append(executor.submit(mastodon_app.follow_user, followee, follower))\n",
    "                    elif random.random() < 0.15:\n",
    "                        futures.append(executor.submit(mastodon_app.follow_user, follower, followee))\n",
    "\n",
    "        # Optionally, wait for all tasks to complete\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            try:\n",
    "                future.result()  # This will raise any exceptions that occurred during execution, if any\n",
    "            except Exception as e:\n",
    "                print(f\"Ignoring already-following error: {e}\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Mastodon display name for each person\n",
    "from mastodon_sim import mastodon_ops\n",
    "if USE_MASTODON_SERVER:\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = [\n",
    "            executor.submit(mastodon_ops.update_bio, user_mapping[name], display_name=name, bio=\"\")\n",
    "            for name in user_mapping\n",
    "        ]\n",
    "    \n",
    "    # Optionally, wait for all tasks to complete\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        future.result()  # This will raise any exceptions that occurred during execution, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "class SimpleGameRunner:\n",
    "    \"\"\"Simplified game master to run players with independent phone scene triggering in parallel.\"\"\"\n",
    "    \n",
    "    def __init__(self, players, clock, action_spec, phones, model, memory, memory_factory):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            players: Dictionary of players.\n",
    "            clock: Game clock to advance time.\n",
    "            action_spec: Action specifications for the players.\n",
    "            phones: Dictionary of phones associated with each player.\n",
    "            model: Language model to process events.\n",
    "            memory: Shared associative memory (could be unique per player if needed).\n",
    "            memory_factory: Factory to create memory instances.\n",
    "        \"\"\"\n",
    "        self.players = {player.name: player for player in players}\n",
    "        self.clock = clock\n",
    "        self.action_spec = action_spec\n",
    "        self.phones = phones\n",
    "        self.model = model\n",
    "        self.memory = memory\n",
    "        self.memory_factory = memory_factory\n",
    "        self.player_components = self._create_player_components()\n",
    "        self.log = []\n",
    "\n",
    "    def _create_player_components(self):\n",
    "        \"\"\"Create a unique SceneTriggeringComponent for each player.\"\"\"\n",
    "        components = {}\n",
    "        for player_name, player in self.players.items():\n",
    "            components[player_name] = triggering.BasicSceneTriggeringComponent(\n",
    "                player=player,\n",
    "                phone=self.phones[player_name],\n",
    "                model=self.model,\n",
    "                memory=self.memory,\n",
    "                clock=self.clock,\n",
    "                memory_factory=self.memory_factory\n",
    "            )\n",
    "        return components\n",
    "\n",
    "    def _step_player(self, player):\n",
    "        \"\"\"Run a single player's action and trigger their phone scene.\"\"\"\n",
    "        try:\n",
    "            # 1. Player takes action\n",
    "            action = player.act(self.action_spec)\n",
    "            event_statement = f\"{player.name} attempted action: {action}\"\n",
    "            \n",
    "            # 2. Log the action (ensure this is thread-safe)\n",
    "            self.log.append({\n",
    "                'player': player.name,\n",
    "                'action': action,\n",
    "                'timestamp': self.clock.now(),\n",
    "            })\n",
    "\n",
    "            # 3. Trigger the phone scene for this player using their unique component\n",
    "            self.player_components[player.name].update_after_event(event_statement)\n",
    "\n",
    "            return event_statement\n",
    "        except Exception as e:\n",
    "            # Handle any player-specific exceptions\n",
    "            return f\"Error for {player.name}: {str(e)}\"\n",
    "\n",
    "    def step(self, active_players=None, timeout=5):\n",
    "        \"\"\"\n",
    "        Run a step for the specified active players in parallel.\n",
    "        \n",
    "        Args:\n",
    "            active_players: List of player names to take part in the step. If None, all players act.\n",
    "            timeout: Timeout in seconds for each player's action.\n",
    "        \"\"\"\n",
    "        if active_players is None:\n",
    "            active_players = list(self.players.keys())\n",
    "\n",
    "        # Use ThreadPoolExecutor to run each player's action and phone event handling in parallel\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            # Submit tasks to be run in parallel, but for each player, action and phone processing are sequential\n",
    "            futures = {executor.submit(self._step_player, self.players[player_name.name]): player_name.name\n",
    "                       for player_name in active_players}\n",
    "\n",
    "            # Wait for all futures to complete, handle timeouts and exceptions\n",
    "            for future in as_completed(futures, timeout=timeout):\n",
    "                player_name = futures[future]\n",
    "                try:\n",
    "                    result = future.result(timeout=timeout)\n",
    "                    print(f\"Result for {player_name}: {result}\")  # This will print the action outcome for each player\n",
    "                except TimeoutError:\n",
    "                    print(f\"Timeout for {player_name}. Skipping their turn.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error in thread for {player_name}: {str(e)}\")\n",
    "\n",
    "        # Advance the game clock after all players' actions are complete\n",
    "        self.clock.advance()\n",
    "\n",
    "    def run_game(self, steps=10):\n",
    "        \"\"\"Run the game for a given number of steps.\"\"\"\n",
    "        for _ in range(steps):\n",
    "            self.step()  # By default, all players will act unless specified otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a custom `CALL_TO_ACTION` prompt for the main Game Master\n",
    "\n",
    "This replaces the [default call to action](https://github.com/google-deepmind/concordia/blob/53697b2bf2019b4a167bdd1f82d14e085f1a5eba/concordia/typing/entity.py#L51).\n",
    "\n",
    "Check out the `Calendar.ipynb` if you haven't already to familarize yourself with the default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concordia.typing.entity import ActionSpec, OutputType\n",
    "\n",
    "\n",
    "CUSTOM_CALL_TO_ACTION = \"\"\"\n",
    "Describe an activity on Storhampton.social that {name} would engage in for the next {timedelta}.\n",
    "Choose actions together take about {timedelta} to complete.\n",
    "It is critical to pay close attention to known information about {name}'s personality,\n",
    "preferences, habits, and background when crafting this activity. The action should be\n",
    "consistent with and reflective of {name}'s established character traits.\n",
    "\n",
    "Some interactions can include :\n",
    "- Observing the toots made by other agents.\n",
    "- Posting on Storhampton.social\n",
    "- Liking other toots\n",
    "- Replying to the toots made by other agents.\n",
    "- Boosting toots made by other agents\n",
    "\n",
    "\n",
    "Example:\n",
    "\n",
    "\"Sarah checks her feed and replies if necessary. Then she may post a toot on Mastodon about her ideas on topic X on the lines of 'Just discovered an intriguing new language for low-latency systems programming.\n",
    "Has anyone given it a try? Curious about potential real-world applications. 🤔\n",
    "#TechNews #ProgrammingLanguages'\"\n",
    "\n",
    "\n",
    "Ensure your response is specific, creative, and detailed. Describe phone-related activities as\n",
    "plans and use future tense or planning language. Always include direct quotes for any planned\n",
    "communication or content creation by {name}, using emojis where it fits the character's style.\n",
    "Most importantly, make sure the activity and any quoted content authentically reflect\n",
    "{name}'s established personality, traits and prior observations. Maintain logical consistency in\n",
    "social media interactions without inventing content from other users. Only reference\n",
    "specific posts or comments from others if they have been previously established or observed.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "action_spec = ActionSpec(\n",
    "   call_to_action=CUSTOM_CALL_TO_ACTION,\n",
    "   output_type=OutputType.FREE,\n",
    "   tag=\"action\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define custom thought chains for the main Game Master\n",
    "\n",
    "This replaces the [default thought chains](https://github.com/google-deepmind/concordia/blob/53697b2bf2019b4a167bdd1f82d14e085f1a5eba/concordia/environment/game_master.py#L38)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the game master object\n",
    "\n",
    "# Experimental version (custom call to action and thought chains)\n",
    "env = SimpleGameRunner(\n",
    "    model=model,\n",
    "    memory=game_master_memory,\n",
    "    phones=phones,\n",
    "    clock=clock,\n",
    "    players=players,\n",
    "    action_spec=action_spec,\n",
    "    memory_factory=blank_memory_factory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_seed_toot(players,p_name):\n",
    "    for player in players:\n",
    "        if player.name == p_name:\n",
    "            call_to_speech = DEFAULT_CALL_TO_SPEECH.format(\n",
    "            name=player.name,\n",
    "            )\n",
    "            interaction_premise = f\"{player.name} has to make their first toot on Mastodon\\n\"\n",
    "            interrogation = interaction_premise\n",
    "            interrogation += \"Thought on Mastodon Toot: In less than 100 words, write a toot that aligns with your views and background.\"\n",
    "            player_says = player.act(action_spec=entity.ActionSpec(call_to_action=\"Context: \" + interrogation +call_to_speech, output_type=entity.OutputType.FREE),)\n",
    "            player_says = player_says.strip(player.name.split()[0]).strip().strip(player.name.split()[1]).strip().strip(\"--\").strip().strip('\"')\n",
    "            print(player.get_last_log())\n",
    "            return player_says"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import threading\n",
    "# import pickle\n",
    "\n",
    "# def clean_for_serialization(entity_agent):\n",
    "#     \"\"\"Removes unpicklable objects like locks before serialization.\"\"\"\n",
    "#     # Reset locks (you can also reinitialize them after loading)\n",
    "#     entity_agent._control_lock = None\n",
    "#     entity_agent._phase_lock = None\n",
    "    \n",
    "#     # If context processors are problematic, you can reset or exclude them as well\n",
    "#     entity_agent._context_processor = None\n",
    "\n",
    "#     return entity_agent\n",
    "\n",
    "\n",
    "# for player in players:\n",
    "#     clean_for_serialization(player)\n",
    "# with open('my_object.pkl', 'wb') as f:\n",
    "#     pickle.dump(players, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the clock to the start time\n",
    "clock.set(START_TIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some observations to seed the players with\n",
    "for player in players:\n",
    "  player.observe( f\"{player.name} is at home, they have just woken up.\")\n",
    "  player.observe( f\"{player.name} remembers they want to update their Mastodon bio.\")\n",
    "  player.observe( f\"{player.name} remembers they want to read their Mastodon feed to catch up on news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallelize the loop using ThreadPoolExecutor\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    # Submit tasks for each agent\n",
    "    futures = [\n",
    "        executor.submit(\n",
    "            lambda agent=agent: (\n",
    "                None if agent[\"seed_toot\"] == \"-\" else\n",
    "                mastodon_app.post_toot(agent[\"name\"], status=agent[\"seed_toot\"]) if agent[\"seed_toot\"] else\n",
    "                mastodon_app.post_toot(agent[\"name\"], status=write_seed_toot(players, agent[\"name\"]))\n",
    "            )\n",
    "        ) \n",
    "        for agent in data[\"agents\"]\n",
    "    ]\n",
    "\n",
    "    # Optionally, wait for all tasks to complete\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        future.result()  # This will raise any exceptions that occurred in the thread, if any\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clock.now())\n",
    "# Possible minutes to pick from\n",
    "minutes_choices = [0, 30]\n",
    "\n",
    "# Generate random datetime objects for each player\n",
    "players_datetimes = {\n",
    "    player: [\n",
    "        datetime.datetime.now().replace(hour=random.randint(0, 23),\n",
    "                                        minute=random.choice(minutes_choices),\n",
    "                                        second=0,\n",
    "                                        microsecond=0)  # Zeroing out seconds and microseconds for cleaner output\n",
    "        for _ in range(15 if player.name in malicious_agents else 5)\n",
    "    ] for player in players\n",
    "}\n",
    "\n",
    "print(players_datetimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import cProfile\n",
    "import pstats\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "# Define the function that writes logs for a player\n",
    "def process_player(player, candidate_agents, agent_config_filename):\n",
    "    result = []\n",
    "    \n",
    "    # Check votes\n",
    "    ans = check_vote(candidate_agents, player)\n",
    "    result.append((f\"{player.name} votes for {ans}\\n\", agent_config_filename + \"votes_log.txt\"))\n",
    "    \n",
    "    # Check political scores\n",
    "    c1 = check_pol(candidate_agents[0], player)\n",
    "    c2 = check_pol(candidate_agents[1], player)\n",
    "    result.append((f\"{player.name} gives {candidate_agents[0].split()[0]} a score of {c1}\\n\", agent_config_filename + \"pol_log.txt\"))\n",
    "    result.append((f\"{player.name} gives {candidate_agents[1].split()[0]} a score of {c2}\\n\", agent_config_filename + \"pol_log.txt\"))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def write_logs(results):\n",
    "    # Write the results to the respective files\n",
    "    for content, file_name in results:\n",
    "        with open(file_name, \"a\") as f:\n",
    "            f.write(content)\n",
    "\n",
    "\n",
    "def read_token_data(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            return data\n",
    "    except FileNotFoundError:\n",
    "        return {'prompt_tokens': 0, 'completion_tokens': 0}\n",
    "\n",
    "episode_length = 240 #961\n",
    "time_intervals=[]\n",
    "prompt_token_intervals = []\n",
    "completion_token_intervals = []\n",
    "player_copy_list=[]\n",
    "# with open(\"../reports/players_all_timesteps.pkl\", \"wb\") as file:\n",
    "if True:\n",
    "    start_time = time.time()  # Start timing\n",
    "    for i in range(episode_length):\n",
    "    # Parallelize the process using ThreadPoolExecutor\n",
    "        if i!=0:    \n",
    "            with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "                # Write the episode logs\n",
    "                    executor.submit(write_logs, [(f\"Episode: {i}\\n\", agent_config_filename + \"votes_log.txt\")])\n",
    "                    executor.submit(write_logs, [(f\"Episode: {i}\\n\", agent_config_filename + \"pol_log.txt\")])            \n",
    "                    # Process each player in parallel\n",
    "                    futures = [executor.submit(process_player, p, candidate_agents, agent_config_filename) for p in players]\n",
    "                    \n",
    "                    # Write each player's results in parallel\n",
    "                    for future in concurrent.futures.as_completed(futures):\n",
    "                        player_results = future.result()\n",
    "                        executor.submit(write_logs, player_results)\n",
    "        print(f\"Episode: {i}\")\n",
    "        with open(\"app_logger.txt\",\"a\") as a:\n",
    "            a.write(f\"Episode: {i}\")\n",
    "\n",
    "        start_timex = time.time()\n",
    "        matching_players = []\n",
    "        # Loop through each player and their associated datetime objects\n",
    "        for player_name, datetimes in players_datetimes.items():\n",
    "            added = False  # Flag to check if player was already added\n",
    "            for datetime_obj in datetimes:\n",
    "                # Check if the hour and minute match the current time (ignoring seconds and microseconds)\n",
    "                if datetime_obj.time().hour == clock.now().hour and datetime_obj.time().minute == clock.now().minute:\n",
    "                    matching_players.append(player_name)\n",
    "                    added = True\n",
    "                    break \n",
    "\n",
    "            # If player is not added by matching time, check for random addition (15% chance)\n",
    "            if not added and random.random() < 0.15:\n",
    "                matching_players.append(player_name)\n",
    "\n",
    "        print(time.time() - start_timex)\n",
    "\n",
    "        # Print the players who matched or were randomly selected\n",
    "        print(\"Players added to the list:\", matching_players)\n",
    "        if len(matching_players)==0:\n",
    "            clock.advance()\n",
    "        else:\n",
    "            env.step(active_players = matching_players)\n",
    "            end_timex = time.time()\n",
    "            with open(\"time_logger.txt\", \"a\") as f:\n",
    "                f.write(f\"Episode with {len(matching_players)} finished - took {end_timex - start_timex}\\n\")\n",
    "    # pickle.dump(players, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and analysis of the episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the entire story\n",
    "all_gm_memories = env._memory.retrieve_recent(k=10000, add_time=True)\n",
    "\n",
    "detailed_story = \"\\n\".join(all_gm_memories)\n",
    "print(\"len(detailed_story): \", len(detailed_story))\n",
    "# print(detailed_story)\n",
    "\n",
    "episode_summary = model.sample_text(\n",
    "    f\"Sequence of events:\\n{detailed_story}\"\n",
    "    \"\\nNarratively summarize the above temporally ordered \"\n",
    "    \"sequence of events. Write it as a news report. Summary:\\n\",\n",
    "     max_tokens=3500,\n",
    "     terminators=(),\n",
    ")\n",
    "print(episode_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarise the perspective of each player\n",
    "player_logs = []\n",
    "player_log_names = []\n",
    "for player in players:\n",
    "  name = player.name\n",
    "  detailed_story = \"\\n\".join(memories[player.name].retrieve_recent(\n",
    "      k=1000, add_time=True))\n",
    "  summary = \"\"\n",
    "  summary = model.sample_text(\n",
    "      f\"Sequence of events that happened to {name}:\\n{detailed_story}\"\n",
    "      \"\\nWrite a short story that summarises these events.\\n\",\n",
    "       max_tokens=3500,\n",
    "       terminators=()\n",
    ")\n",
    "\n",
    "  all_player_mem = memories[player.name].retrieve_recent(k=1000, add_time=True)\n",
    "  all_player_mem = [\"Summary:\", summary, \"Memories:\", *all_player_mem]\n",
    "  player_html = html_lib.PythonObjectToHTMLConverter(all_player_mem).convert()\n",
    "  player_logs.append(player_html)\n",
    "  player_log_names.append(f\"{name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and display HTML log of the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_sources = [env, direct_effect_externality]\n",
    "histories_html = [html_lib.PythonObjectToHTMLConverter(history.get_history()).convert() for history in history_sources]\n",
    "histories_names = [history.name for history in history_sources]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_mem_html = html_lib.PythonObjectToHTMLConverter(all_gm_memories).convert()\n",
    "\n",
    "tabbed_html = html_lib.combine_html_pages(\n",
    "    [*histories_html, gm_mem_html, *player_logs],\n",
    "    [*histories_names, \"GM\", *player_log_names],\n",
    "    summary=episode_summary,\n",
    "    title=\"Mastodon experiment\",\n",
    ")\n",
    "\n",
    "tabbed_html = html_lib.finalise_html(tabbed_html)\n",
    "with open(\"index5-55.html\",\"w\",encoding=\"utf-8\") as f:\n",
    "    f.write(tabbed_html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.HTML(tabbed_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interact with a specific player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_to_interact = \"Alice\"\n",
    "user_identity = \"a close friend\"\n",
    "interaction_premise = f\"{sim_to_interact} is talking to {user_identity}\\n\"\n",
    "\n",
    "player_names = [player.name for player in players]\n",
    "player_by_name = {player.name: player for player in players}\n",
    "selected_player = player_by_name[sim_to_interact]\n",
    "interrogation = interaction_premise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterance_from_user = (\n",
    "    \"Hey Alice, did you post anything on Mastodon today?\"\n",
    ")\n",
    "\n",
    "interrogation += f\"{user_identity}: {utterance_from_user}\"\n",
    "player_says = selected_player.say(interrogation)\n",
    "interrogation += f\"\\n{sim_to_interact}: {player_says}\\n\"\n",
    "print(interrogation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check timeline\n",
    "\n",
    "Finally, check the full public timeline for the Mastodon server.\n",
    "\n",
    "You may also check this directly at https://social-sandbox.com (you'll need to log in as a user)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeline = get_public_timeline(limit=None)\n",
    "print_timeline(timeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
