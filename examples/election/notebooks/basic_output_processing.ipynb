{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4890b769-a2a0-4bdf-87c9-ca1c4ea9b2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/maxpu/Dropbox/scripts/Projects/socialsandbox/mastodon-sim\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import json\n",
    "import os\n",
    "import yaml\n",
    "current_path = os.getcwd()\n",
    "print(current_path)\n",
    "assert current_path.split('/')[-1]==\"mastodon-sim\", \"run the notebook from project root!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a088eb-d779-4d62-9507-a62c8ef35b82",
   "metadata": {},
   "source": [
    "load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d0663e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project root: /mnt/c/Users/maxpu/Dropbox/scripts/Projects/socialsandbox/mastodon-sim\n",
      "/mnt/c/Users/maxpu/Dropbox/scripts/Projects/socialsandbox/mastodon-sim/examples/election/output/\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ROOT = current_path\n",
    "print(\"project root: \" + str(PROJECT_ROOT))\n",
    "abs_rootpath = PROJECT_ROOT + \"/examples/election/output/\"\n",
    "print(abs_rootpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815a236e-50ce-4df8-80b8-5c48c7f8965d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# in output_proc_utils.py\n",
    "\n",
    "import collections\n",
    "\n",
    "def load_data(fileroot, names_of_focalplayers):\n",
    "    with open(fileroot +\".yaml\") as file:\n",
    "        config_data = yaml.safe_load(file)\n",
    "    print(fileroot + \"_events.jsonl\")\n",
    "    df = pd.read_json(fileroot + \"_events.jsonl\", lines=True)\n",
    "\n",
    "    pd.set_option(\"display.width\", 1000)\n",
    "    print(df.head())\n",
    "    print()\n",
    "    print(\"Probes:\")\n",
    "    print(df.loc[df.event_type == \"probe\", \"label\"].value_counts())\n",
    "    print()\n",
    "    print(\"Actions:\")\n",
    "    print(df.loc[(df.event_type == \"action\") & (df.episode > -1), \"label\"].value_counts())\n",
    "    print()\n",
    "    print(\n",
    "        df.loc[(df.event_type == \"action\") & (df.episode > -1), \"data\"]\n",
    "        .apply(lambda x: x.keys())\n",
    "        .value_counts()\n",
    "    )\n",
    "    print()\n",
    "    print(\n",
    "        df.loc[\n",
    "            (df.source_user.isin(names_of_focalplayers))\n",
    "            & (df.event_type == \"action\")\n",
    "            & (df.episode > -1)\n",
    "        ]\n",
    "        .groupby(\"source_user\")[\"label\"]\n",
    "        .value_counts()\n",
    "    )\n",
    "    print()\n",
    "    print(\"post\")\n",
    "    posts = df.loc[\n",
    "        (df.label == \"post\") & (df.episode > -1) & (df.source_user != \"storhampton_gazette\"),\n",
    "        [\"source_user\", \"data\"],\n",
    "    ]\n",
    "    users = posts[\"source_user\"].values\n",
    "    posts = posts[\"data\"].apply(lambda x: x[\"post_text\"]).values\n",
    "    for user, post in zip(users, posts):\n",
    "        print(f\"source_user:{user}:{post}\")\n",
    "    print()\n",
    "    print(\"reply\")\n",
    "    replies = df.loc[\n",
    "        (df.label == \"reply\") & (df.episode > -1) & (df.source_user != \"storhampton_gazette\"),\n",
    "        [\"source_user\", \"episode\", \"data\"],\n",
    "    ]\n",
    "    users = replies[\"source_user\"].values\n",
    "    replies = replies[\"data\"].apply(lambda x: x[\"post_text\"]).values\n",
    "    for user, reply in zip(users, replies):\n",
    "        print(f\"source_user:{user}:{reply}\")\n",
    "    print()\n",
    "    dftmp = df.copy()\n",
    "    dftmp = dftmp.loc[(dftmp.event_type == \"action\") & (dftmp.episode > -1), :]\n",
    "    dftmp[\"data\"] = dftmp[\"data\"].apply(str)\n",
    "    print(f\"{(len(dftmp) - len(dftmp.drop_duplicates())) / len(dftmp):.3f} duplicate fraction\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def post_process_output(df):\n",
    "    eval_df = df.loc[\n",
    "        df.event_type == \"eval\", [\"episode\", \"source_user\", \"label\", \"data\"]\n",
    "    ].reset_index(drop=True)\n",
    "    eval_df[\"response\"] = eval_df.data.apply(lambda x: x[\"query_return\"])\n",
    "    eval_df = eval_df.drop(\"data\", axis=1)\n",
    "\n",
    "    edge_df = df.loc[\n",
    "        df.label.isin([\"follow\", \"unfollow\"]), [\"episode\", \"source_user\", \"data\", \"label\"]\n",
    "    ].reset_index(drop=True)\n",
    "    edge_df[\"target_user\"] = edge_df.data.apply(lambda d: d[\"target_user\"])\n",
    "    edge_df = edge_df.drop(\"data\", axis=1)\n",
    "\n",
    "    interaction_types = [\"post\", \"like_toot\", \"boost_toot\", \"reply\"]\n",
    "    int_df = df.loc[df.label.isin(interaction_types), :].reset_index(drop=True)\n",
    "    return eval_df, int_df, edge_df\n",
    "\n",
    "\n",
    "def episodewise_graphbuild(edge_df):\n",
    "    follow_graph = nx.DiGraph()\n",
    "    for epi_edge_data in edge_df.groupby(\"episode\"):\n",
    "        for action, operate_on_graph in zip(\n",
    "            [\"follow\", \"unfollow\"], [follow_graph.add_edges_from, follow_graph.remove_edges_from]\n",
    "        ):\n",
    "            if (epi_edge_data.label == action).any():\n",
    "                data = epi_edge_data.loc[\n",
    "                    epi_edge_data.label == action, [\"source_user\", \"target_user\"]\n",
    "                ]\n",
    "                operate_on_graph(list(data.itertuples(index=False, name=None)))\n",
    "    return follow_graph\n",
    "\n",
    "\n",
    "# in dashboard-basic.py:\n",
    "\n",
    "\n",
    "def get_target_user(row):\n",
    "    if row.label == \"post\":\n",
    "        target_user = row.source_user\n",
    "    elif row.label == \"like_toot\":\n",
    "        target_user = row.data[\"target_user\"]\n",
    "    elif row.label == \"boost_toot\":\n",
    "        target_user = row.data[\"target_user\"]\n",
    "    elif row.label == \"reply\":\n",
    "        target_user = row.data[\"reply_to\"][\"target_user\"]\n",
    "    return target_user\n",
    "\n",
    "\n",
    "def get_int_dict(int_df):\n",
    "    past = dict(\n",
    "        zip([\"post\", \"like_toot\", \"boost_toot\", \"reply\"], [\"posted\", \"liked\", \"boosted\", \"replied\"])\n",
    "    )\n",
    "    int_df[\"int_data\"] = int_df.apply(\n",
    "        lambda x: {\n",
    "            \"action\": past[x.label],\n",
    "            \"episode\": x.episode,\n",
    "            \"source_user\": x.source_user,\n",
    "            \"target_user\": get_target_user(x),\n",
    "            \"toot_id\": x.data[\"toot_id\"],\n",
    "        },\n",
    "        axis=1,\n",
    "    )\n",
    "    int_df.int_data = int_df.apply(\n",
    "        lambda x: x.int_data | {\"parent_toot_id\": x.data[\"reply_to\"][\"toot_id\"]}\n",
    "        if x.label == \"reply\"\n",
    "        else x.int_data,\n",
    "        axis=1,\n",
    "    )\n",
    "    return int_df.groupby(\"episode\")[\"int_data\"].apply(list).to_dict()\n",
    "\n",
    "\n",
    "def get_toot_dict(int_df):\n",
    "    past = dict(\n",
    "        zip([\"post\", \"like_toot\", \"boost_toot\", \"reply\"], [\"posted\", \"liked\", \"boosted\", \"replied\"])\n",
    "    )\n",
    "    text_df = int_df.loc[(int_df.label == \"post\") | (int_df.label == \"reply\"), :].reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "\n",
    "    # handle Nones as toot_ids by appending an index\n",
    "    no_toot_id = text_df.data.apply(lambda x: x[\"toot_id\"] is None)\n",
    "    text_df[\"no_toot_id_idx\"] = -1\n",
    "    text_df.loc[no_toot_id, \"no_toot_id_idx\"] = range(no_toot_id.sum())\n",
    "    text_df.loc[no_toot_id, \"data\"] = text_df.loc[no_toot_id, :].apply(\n",
    "        lambda x: x.data | {\"toot_id\": \"None\" + str(x.no_toot_id_idx)}, axis=1\n",
    "    )\n",
    "\n",
    "    text_df[\"toot_id\"] = text_df.data.apply(lambda x: x[\"toot_id\"])\n",
    "    text_df = text_df.set_index(\"toot_id\")\n",
    "    text_df[\"text_data\"] = text_df.apply(\n",
    "        lambda x: {\"user\": x.source_user, \"action\": past[x.label], \"content\": x.data[\"post_text\"]},\n",
    "        axis=1,\n",
    "    )\n",
    "    text_df.text_data = text_df.apply(\n",
    "        lambda x: x.text_data | {\"parent_toot_id\": x.data[\"reply_to\"][\"toot_id\"]}\n",
    "        if x.label == \"reply\"\n",
    "        else x.text_data,\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    return text_df.text_data.to_dict()\n",
    "\n",
    "\n",
    "def load_data_dash(eval_df, int_df, edge_df):\n",
    "    # votes\n",
    "    votes = (\n",
    "        eval_df.loc[eval_df.label == \"vote_pref\", [\"source_user\", \"response\", \"episode\"]]\n",
    "        .groupby(\"episode\")\n",
    "        .apply(lambda x: dict(zip(x.source_user, x.response)))\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "    # final follow network\n",
    "    follow_graph = nx.from_pandas_edgelist(\n",
    "        edge_df, \"source_user\", \"target_user\", create_using=nx.DiGraph()\n",
    "    )  # invalid in presence of unfollows (in which case use episodewise_graphbuild)\n",
    "\n",
    "    # active users with episode keys\n",
    "    posted_users_by_episode = int_df.groupby(\"episode\")[\"source_user\"].apply(set).to_dict()\n",
    "\n",
    "    # interaction data\n",
    "    int_dict = get_int_dict(int_df.copy())\n",
    "\n",
    "    # toot_data\n",
    "    toot_dict = get_toot_dict(int_df.copy())\n",
    "\n",
    "    return follow_graph, int_dict, posted_users_by_episode, toot_dict, votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c6487ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/maxpu/Dropbox/scripts/Projects/socialsandbox/mastodon-sim/examples/election/output/N20_T1_Reddit_Big5_independent_v1_news_no_bias_with_images_run1_19_23_14_03_2025/N20_T1_Reddit_Big5_independent_v1_news_no_bias_with_images_run1_19_23_14_03_2025_events.jsonl\n",
      "         source_user   label                                               data  episode event_type\n",
      "0  Jessica Rodriguez  follow  {'target_user': 'Sam Jenkins', 'suggested_acti...       -1     action\n",
      "1      Alex Thompson  follow  {'target_user': 'Emily Chen', 'suggested_actio...       -1     action\n",
      "2      Alex Thompson  follow  {'target_user': 'Michael Harris', 'suggested_a...       -1     action\n",
      "3      Nathan Torres  follow  {'target_user': 'Zachary Patel', 'suggested_ac...       -1     action\n",
      "4      Nathan Torres  follow  {'target_user': 'Jason Miller', 'suggested_act...       -1     action\n",
      "\n",
      "Evals:\n",
      "Series([], Name: count, dtype: int64)\n",
      "\n",
      "Actions:\n",
      "label\n",
      "get_own_timeline    5\n",
      "post                2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "data\n",
      "(num_posts_retreived, suggested_action)    5\n",
      "(toot_id, post_text, suggested_action)     2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Series([], Name: count, dtype: int64)\n",
      "\n",
      "post\n",
      "source_user:Michael Robertson:Just woke up and ready to dive into the latest election discussions about social justice and environmental protection!\n",
      "source_user:Laura Mitchell:I'm excited to share my thoughts on the candidates and the importance of voting in the upcoming election!\n",
      "\n",
      "reply\n",
      "\n",
      "0.000 duplicate fraction\n"
     ]
    }
   ],
   "source": [
    "run_name = \"N20_T1_Reddit_Big5_independent_v1_news_no_bias_with_images_run1_19_23_14_03_2025\"\n",
    "names_of_focalplayers = [\"Bill Fredrickson\", \"Bradley Carter\"]\n",
    "df = load_data(abs_rootpath + run_name+ \"/\"+run_name, names_of_focalplayers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6436ac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as pl\n",
    "\n",
    "#copy from voter model file\n",
    "action_probabilities = {\n",
    "    # High frequency actions\n",
    "    \"like_toot\": 0.35,  # Most common action\n",
    "    \"boost_toot\": 0.15,  # Common but less than likes\n",
    "    \"post\": 0.20,  # Regular posting\n",
    "    \"reply\": 0.15,\n",
    "    # Medium frequency actions\n",
    "    \"follow\": 0.15,  # Following new accounts\n",
    "    \"unfollow\": 0.00,  # 25,  # Unfollowing accounts\n",
    "    \"print_timeline\": 0.0,  # Reading timeline\n",
    "    # Low frequency actions\n",
    "    \"block_user\": 0.0,  # Blocking problematic users\n",
    "    \"unblock_user\": 0.0,  # Unblocking users\n",
    "    \"delete_posts\": 0.0,  # Deleting own posts\n",
    "    \"update_bio\": 0.0,  # Updating profile\n",
    "    \"print_notifications\": 0.00,  # 25,  # Checking notifications\n",
    "}\n",
    "\n",
    "fig, ax = pl.subplots()\n",
    "dft = df.loc[\n",
    "    (df.event_type == \"action\") & (df.episode > -1) & ~(df.source_user.isin(names_of_focalplayers)),\n",
    "    :,\n",
    "].copy()\n",
    "dft[\"suggested_action\"] = dft[\"data\"].apply(\n",
    "    lambda x: \"post\" if x[\"suggested_action\"] == \"toot\" else x[\"suggested_action\"]\n",
    ")\n",
    "sns.histplot(\n",
    "    data=dft.loc[:, [\"label\", \"suggested_action\"]].melt(),\n",
    "    ax=ax,\n",
    "    x=\"value\",\n",
    "    hue=\"variable\",\n",
    "    multiple=\"dodge\",\n",
    "    shrink=0.75,\n",
    "    bins=20,\n",
    ")\n",
    "dft\n",
    "action_list = [obj.get_text() for obj in ax.get_xticklabels()]\n",
    "ax.plot(\n",
    "    range(len(action_list)),\n",
    "    [action_probabilities[action] * len(dft) for action in action_list],\n",
    "    \".-\",\n",
    ")\n",
    "ax.set_title(\"line is expected count from suggested freqs\")\n",
    "fig, ax = pl.subplots()\n",
    "contingency = pd.crosstab(dft[\"suggested_action\"], df[\"label\"])\n",
    "sns.heatmap(\n",
    "    contingency,\n",
    "    ax=ax,\n",
    "    annot=True,  # Show numbers in cells\n",
    "    fmt=\"d\",  # Format as integers\n",
    "    cmap=\"YlOrRd\",  # Yellow-Orange-Red color scheme\n",
    "    cbar_kws={\"label\": \"Count\"},\n",
    "    square=True,\n",
    ")  # Make cells square\n",
    "ax.set_ylabel(\"action taken\")\n",
    "ax.set_ylabel(\"suggested action\")\n",
    "ax.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df00ca04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
